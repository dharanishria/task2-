{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6203292,"sourceType":"datasetVersion","datasetId":3561514}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nIn this project, we aim to predict the traffic volume on I-94 Interstate highway using various features like weather conditions, time of the day, whether the day is a holiday or not, etc. The dataset used for this project was obtained from Kaggle and contains hourly data from 2012 to 2018.","metadata":{}},{"cell_type":"markdown","source":"# Data Collection\nIn this step, we will download the dataset from the provided Kaggle link and read the dataset description and other available metadata to understand the context of the data.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:58:17.145803Z","iopub.execute_input":"2023-07-31T11:58:17.146216Z","iopub.status.idle":"2023-07-31T11:58:17.176804Z","shell.execute_reply.started":"2023-07-31T11:58:17.146181Z","shell.execute_reply":"2023-07-31T11:58:17.176073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/metro-interstate-traffic-volume/Metro_Interstate_Traffic_Volume.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:58:17.178524Z","iopub.execute_input":"2023-07-31T11:58:17.179394Z","iopub.status.idle":"2023-07-31T11:58:17.285555Z","shell.execute_reply.started":"2023-07-31T11:58:17.179367Z","shell.execute_reply":"2023-07-31T11:58:17.284285Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the first few rows of the DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:58:17.287003Z","iopub.execute_input":"2023-07-31T11:58:17.28755Z","iopub.status.idle":"2023-07-31T11:58:17.315795Z","shell.execute_reply.started":"2023-07-31T11:58:17.287523Z","shell.execute_reply":"2023-07-31T11:58:17.314224Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Description\nThe dataset contains hourly data on the traffic volume for westbound I-94, a major interstate highway in the US that connects Minneapolis and St Paul, Minnesota. The data was collected by the Minnesota Department of Transportation (MnDOT) from 2012 to 2018 at a station roughly midway between the two cities.\n\nThe dataset has 48204 instances and 9 attributes. The attributes are:\n\n- holiday: a categorical variable that indicates whether the date is a US national holiday or a regional holiday (such as the Minnesota State Fair).\n- temp: a numeric variable that shows the average temperature in kelvin.\n- rain_1h: a numeric variable that shows the amount of rain in mm that occurred in the hour.\n- snow_1h: a numeric variable that shows the amount of snow in mm that occurred in the hour.\n- clouds_all: a numeric variable that shows the percentage of cloud cover.\n- weather_main: a categorical variable that gives a short textual description of the current weather (such as Clear, Clouds, Rain, etc.).\n- weather_description: a categorical variable that gives a longer textual description of the current weather (such as light rain, overcast clouds, etc.).\n- date_time: a datetime variable that shows the hour of the data collected in local CST time.\n- traffic_volume: a numeric variable that shows the hourly I-94 reported westbound traffic volume.","metadata":{}},{"cell_type":"code","source":"# Display the shape of the DataFrame\nprint(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns\")\n\n# Display the data types of each column\nprint(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:58:25.409574Z","iopub.execute_input":"2023-07-31T11:58:25.409952Z","iopub.status.idle":"2023-07-31T11:58:25.417365Z","shell.execute_reply.started":"2023-07-31T11:58:25.40992Z","shell.execute_reply":"2023-07-31T11:58:25.415977Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)\nIn this step, we will perform an initial exploration of the data, check for missing values, perform statistical analysis, and visualize the data to understand the distribution and relationship between different variables.\n","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = df.isnull().sum()\nprint(f\"Missing values in each column:\\n{missing_values}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:59:17.979906Z","iopub.execute_input":"2023-07-31T11:59:17.980257Z","iopub.status.idle":"2023-07-31T11:59:18.017004Z","shell.execute_reply.started":"2023-07-31T11:59:17.980233Z","shell.execute_reply":"2023-07-31T11:59:18.016146Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Perform statistical analysis\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:59:23.831833Z","iopub.execute_input":"2023-07-31T11:59:23.832144Z","iopub.status.idle":"2023-07-31T11:59:23.870412Z","shell.execute_reply.started":"2023-07-31T11:59:23.832121Z","shell.execute_reply":"2023-07-31T11:59:23.868893Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visualization\nLet's visualize the data to understand the distribution and relationship between different variables.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Histogram of traffic volume\nplt.figure(figsize=(10,6))\nsns.histplot(df['traffic_volume'], kde=True)\nplt.title('Distribution of Traffic Volume')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:59:38.352066Z","iopub.execute_input":"2023-07-31T11:59:38.352484Z","iopub.status.idle":"2023-07-31T11:59:39.470197Z","shell.execute_reply.started":"2023-07-31T11:59:38.352452Z","shell.execute_reply":"2023-07-31T11:59:39.469095Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bar plot of weather_main\nplt.figure(figsize=(10,6))\nsns.countplot(x='weather_main', data=df)\nplt.title('Weather Conditions')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:59:43.96159Z","iopub.execute_input":"2023-07-31T11:59:43.962005Z","iopub.status.idle":"2023-07-31T11:59:44.245375Z","shell.execute_reply.started":"2023-07-31T11:59:43.961977Z","shell.execute_reply":"2023-07-31T11:59:44.244244Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scatter plot of traffic_volume vs temp\nplt.figure(figsize=(10,6))\nsns.scatterplot(x='temp', y='traffic_volume', data=df)\nplt.title('Traffic Volume vs Temperature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T11:59:50.850228Z","iopub.execute_input":"2023-07-31T11:59:50.850603Z","iopub.status.idle":"2023-07-31T11:59:51.161173Z","shell.execute_reply.started":"2023-07-31T11:59:50.850571Z","shell.execute_reply":"2023-07-31T11:59:51.160121Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering\nIn this step, we will extract useful features from the 'date_time' column, convert categorical variables into numerical format, and normalize or standardize numerical features if required.","metadata":{}},{"cell_type":"code","source":"# Convert 'date_time' to datetime format\ndf['date_time'] = pd.to_datetime(df['date_time'])\n\n# Extract features from 'date_time'\ndf['hour'] = df['date_time'].dt.hour\ndf['day_of_week'] = df['date_time'].dt.dayofweek\ndf['month'] = df['date_time'].dt.month","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:00:57.645746Z","iopub.execute_input":"2023-07-31T12:00:57.646097Z","iopub.status.idle":"2023-07-31T12:01:01.625585Z","shell.execute_reply.started":"2023-07-31T12:00:57.646072Z","shell.execute_reply":"2023-07-31T12:01:01.624497Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert categorical variables into numerical format using one-hot encoding\ndf = pd.get_dummies(df, columns=['weather_main', 'weather_description', 'holiday'])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:01:09.76302Z","iopub.execute_input":"2023-07-31T12:01:09.763408Z","iopub.status.idle":"2023-07-31T12:01:09.810208Z","shell.execute_reply.started":"2023-07-31T12:01:09.763377Z","shell.execute_reply":"2023-07-31T12:01:09.809148Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Here, standardizing 'temp', 'rain_1h', 'snow_1h', and 'clouds_all'\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf[['temp', 'rain_1h', 'snow_1h', 'clouds_all']] = scaler.fit_transform(df[['temp', 'rain_1h', 'snow_1h', 'clouds_all']])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:01:11.774067Z","iopub.execute_input":"2023-07-31T12:01:11.774468Z","iopub.status.idle":"2023-07-31T12:01:11.867457Z","shell.execute_reply.started":"2023-07-31T12:01:11.774436Z","shell.execute_reply":"2023-07-31T12:01:11.866455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Selection\nIn this step, we will split the data into training and testing sets, choose a suitable model for regression tasks, and train the model on the training data.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Define the features and the target\nX = df.drop(['traffic_volume', 'date_time'], axis=1)\ny = df['traffic_volume']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:01:59.60071Z","iopub.execute_input":"2023-07-31T12:01:59.601083Z","iopub.status.idle":"2023-07-31T12:01:59.862536Z","shell.execute_reply.started":"2023-07-31T12:01:59.601057Z","shell.execute_reply":"2023-07-31T12:01:59.861598Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Linear Regression\nWe will start with a simple Linear Regression model.","metadata":{}},{"cell_type":"code","source":"# Initialize the Linear Regression model\nlr = LinearRegression()\n\n# Train the model on the training data\nlr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:02:02.084306Z","iopub.execute_input":"2023-07-31T12:02:02.085207Z","iopub.status.idle":"2023-07-31T12:02:02.207956Z","shell.execute_reply.started":"2023-07-31T12:02:02.085175Z","shell.execute_reply":"2023-07-31T12:02:02.207123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation\nIn this step, we will evaluate the model on the testing data using appropriate metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), or Root Mean Squared Error (RMSE). We will also analyze the residuals to check if they follow a normal distribution.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport numpy as np\n\n# Predict on the testing data\ny_pred = lr.predict(X_test)\n\n# Calculate MAE, MSE, and RMSE\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\n\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:02:46.497465Z","iopub.execute_input":"2023-07-31T12:02:46.497862Z","iopub.status.idle":"2023-07-31T12:02:46.518983Z","shell.execute_reply.started":"2023-07-31T12:02:46.497827Z","shell.execute_reply":"2023-07-31T12:02:46.516761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Residual Analysis\nLet's analyze the residuals to check if they follow a normal distribution.","metadata":{}},{"cell_type":"code","source":"# Calculate residuals\nresiduals = y_test - y_pred\n\n# Plot the residuals\nplt.figure(figsize=(10,6))\nsns.histplot(residuals, kde=True)\nplt.title('Residuals')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:02:56.413743Z","iopub.execute_input":"2023-07-31T12:02:56.41411Z","iopub.status.idle":"2023-07-31T12:02:56.728189Z","shell.execute_reply.started":"2023-07-31T12:02:56.41408Z","shell.execute_reply":"2023-07-31T12:02:56.727312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Optimization\nIn this step, we will perform hyperparameter tuning using Grid Search. We will also use cross-validation during this process to ensure that our model generalizes well to unseen data.","metadata":{}},{"cell_type":"markdown","source":"**Grid Search**\n\nLet's use Grid Search to find the optimal hyperparameters for our Linear Regression model.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the grid of hyperparameters\nparam_grid = {'fit_intercept': [True, False]}\n\n# Initialize the Grid Search model\ngrid_search = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error')\n\n# Fit the model to the training data\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:04:45.75872Z","iopub.execute_input":"2023-07-31T12:04:45.759059Z","iopub.status.idle":"2023-07-31T12:04:47.279639Z","shell.execute_reply.started":"2023-07-31T12:04:45.759031Z","shell.execute_reply":"2023-07-31T12:04:47.278667Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Best Parameters**\n\nLet's check the best parameters found by Grid Search.","metadata":{}},{"cell_type":"code","source":"# Print the best parameters\nprint(f\"Best parameters: {grid_search.best_params_}\")\n\n# Print the best score\nprint(f\"Best score: {grid_search.best_score_}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:04:55.355807Z","iopub.execute_input":"2023-07-31T12:04:55.356236Z","iopub.status.idle":"2023-07-31T12:04:55.360934Z","shell.execute_reply.started":"2023-07-31T12:04:55.356203Z","shell.execute_reply":"2023-07-31T12:04:55.360234Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Deployment\nIn this step, we will save the trained model using joblib. This model can then be loaded in a different environment and used for prediction.","metadata":{}},{"cell_type":"code","source":"# Import necessary library\nimport joblib\n\n# Save the model\njoblib.dump(grid_search.best_estimator_, 'traffic_volume_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:05:37.580656Z","iopub.execute_input":"2023-07-31T12:05:37.581031Z","iopub.status.idle":"2023-07-31T12:05:37.588723Z","shell.execute_reply.started":"2023-07-31T12:05:37.581005Z","shell.execute_reply":"2023-07-31T12:05:37.587888Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Use the Model for Prediction\nNow, we will write a Kaggle kernel where we load the model and use it for prediction.","metadata":{}},{"cell_type":"code","source":"# Load the model\nloaded_model = joblib.load('traffic_volume_model.pkl')\n\n# Use the model for prediction\n# Here, we are using the first 10 rows of the testing data for demonstration\nsample_data = X_test.iloc[:10]\npredictions = loaded_model.predict(sample_data)\n\n# Print the predictions\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:05:39.228237Z","iopub.execute_input":"2023-07-31T12:05:39.228872Z","iopub.status.idle":"2023-07-31T12:05:39.238784Z","shell.execute_reply.started":"2023-07-31T12:05:39.228841Z","shell.execute_reply":"2023-07-31T12:05:39.23735Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\nIn this project, I created a machine learning model to predict the traffic volume on the I-94 Interstate highway. The model can be used by traffic management systems, navigation applications or logistics companies to plan their routes more efficiently.\n\n## Future Work\nIn the future, we can try more complex models like Random Forest, Gradient Boosting, or Neural Networks to see if they can improve the performance. We can also explore more feature engineering techniques to extract more useful information from the data.","metadata":{}}]}